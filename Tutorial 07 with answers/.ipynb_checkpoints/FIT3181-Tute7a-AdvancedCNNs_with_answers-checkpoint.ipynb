{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT3181: Deep Learning (2021)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head TA:*  **Mr Thanh Nguyen** | thanh.nguyen4@monash.edu <br/>\n",
    "*Tutor:* **Dr Van Nguyen**  \\[van.nguyen1@monash.edu \\] | **Mr James Tong** \\[james.tong1@monash.edu\\] | **Dr Mahmoud Mohammad** \\[mahmoud.hossam@monash.edu\\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Tutorial 7a: Advanced Convolutional Neural Networks</span> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this tutorial is to show you how to implement ResNet, the most popular CNN model. This ResNet implementation follows the original paper of ResNet.**\n",
    "\n",
    "\n",
    "**Acknowledgement:** *This tutorial is developed based on the material in chapter 7 of the book Dive Into Deep Learning*.\n",
    "\n",
    "**References and additional reading and resources**\n",
    "- Chapter 7 of Dive Into Deep Learning ([link](https://d2l.ai/chapter_convolutional-modern/index.html)).\n",
    "\n",
    "**Hint**: The implementations of ResNet in this tutorial would facilitate you in doing Part 3 of assignment 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">I. Implementation of Residual Network (ResNet)</span> <span style=\"color:red\">****</span> ##\n",
    "This is a **highly recommend-to-learn** knowledge because ResNet is the most widely popular architecture used in computer vision tasks. Moreover, we can apply what is learned here to assignment 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.1. Residual Block</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building block of ResNet is the **residual block** which has the following architecture: *[CONV2D, BatchNorm, RELU, CONV2D, BatchNorm]* together with the skip connection. For the skip connection, we have two options: `use 1x1 CONV1D` or `not use 1x1 CONV1D`. The following figure shows the architecture of the residual block for two options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/ResidualBlock.png\" align=\"center\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we are going to implement the class `Residual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "class Residual(tf.keras.Model):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same', kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3, padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return tf.keras.activations.relu(Y)\n",
    "\n",
    "blk = Residual(num_channels=3, use_1x1conv=True, strides=1)\n",
    "X = tf.random.uniform((10, 32, 32, 3))\n",
    "Y = blk(X)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the case when we do not apply 1x1 Conv1D, hence it requires the `num_channels` is equal to the `input_depth` (equal to 3 in the following example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 6, 6, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3)\n",
    "X = tf.random.uniform((4, 6, 6, 3))\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply 1x1 Conv1D, the output shape of the residual block can be different from the input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 3, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.2. ResNet Block</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement **ResNet block**. A ResNet block consists of several residual blocks and we need to declare the number of residual blocks as `num_residuals` and the common number of channels of residual blocks in a ResNet block as `num_channels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_residuals, first_block=False, **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                self.residual_layers.append(\n",
    "                    Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual(num_channels))\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that from the second ResNet block, we apply `1x1 Conv1D` over the skip connection of every first residual block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.3. Residual Network</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now declare our ResNet. Note that we set `input_shape = [28,28,1]` because we will train our ResNet on Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ResNet():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', input_shape = [28,28,1]),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "        ResnetBlock(64, 2, first_block=True),\n",
    "        ResnetBlock(128, 2),\n",
    "        ResnetBlock(256, 2),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Dense(units=10, activation= 'softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed a batch $X$ with batch size $1$ to our ResNet and print out the output shapes. Your task is to explain the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 14, 14, 64)\n",
      "BatchNormalization output shape:\t (1, 14, 14, 64)\n",
      "Activation output shape:\t (1, 14, 14, 64)\n",
      "MaxPooling2D output shape:\t (1, 7, 7, 64)\n",
      "ResnetBlock output shape:\t (1, 7, 7, 64)\n",
      "ResnetBlock output shape:\t (1, 4, 4, 128)\n",
      "ResnetBlock output shape:\t (1, 2, 2, 256)\n",
      "GlobalAveragePooling2D output shape:\t (1, 256)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 28, 28, 1))\n",
    "for layer in create_ResNet().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.4. Test our ResNet</span> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,)\n",
      "(50000, 28, 28, 1) (50000,)\n",
      "(10000, 28, 28, 1) (10000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full) , (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full, X_test = X_train_full/255.0, X_test/255.0\n",
    "X_train_full = np.expand_dims(X_train_full, axis=-1)   #expand one more dimension at the end and obtain [60000, 28, 28,1]\n",
    "X_test = np.expand_dims(X_test, axis=-1)   #expand one more dimension at the end and obtain [10000, 28, 28,1]\n",
    "X_train, X_valid = X_train_full[:50000,:], X_train_full[50000:,:]\n",
    "y_train, y_valid = y_train_full[:50000], y_train_full[50000:]\n",
    "print(X_train_full.shape, y_train_full.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 0.4283 - accuracy: 0.8437 - val_loss: 0.3487 - val_accuracy: 0.8673\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.2978 - accuracy: 0.8906 - val_loss: 0.3766 - val_accuracy: 0.8601\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 70s 89ms/step - loss: 0.2544 - accuracy: 0.9046 - val_loss: 0.2874 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.2331 - accuracy: 0.9135 - val_loss: 0.2776 - val_accuracy: 0.8998\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.2088 - accuracy: 0.9214 - val_loss: 0.2605 - val_accuracy: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246ee6b3310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_resnet = create_ResNet()\n",
    "my_resnet.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "my_resnet.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 1</span>**: Implement VGG network and test on Fashion MNIST dataset. Note that you can refer to the code [here](https://d2l.ai/chapter_convolutional-modern/vgg.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3, padding='same',activation='relu'))\n",
    "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    net = tf.keras.models.Sequential()\n",
    "    # The convulational part\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # The fully-connected part\n",
    "    net.add(tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation= 'softmax')]))\n",
    "    return net\n",
    "\n",
    "conv_arch = ((1, 16), (2, 32))\n",
    "vgg_net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 14, 14, 16)\n",
      "Sequential output shape:\t (1, 7, 7, 32)\n",
      "Sequential output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 28, 28, 1))\n",
    "for blk in vgg_net.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 81s 104ms/step - loss: 0.5817 - accuracy: 0.7909 - val_loss: 0.3902 - val_accuracy: 0.8600\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 87s 111ms/step - loss: 0.3621 - accuracy: 0.8702 - val_loss: 0.3391 - val_accuracy: 0.8740\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 85s 108ms/step - loss: 0.3083 - accuracy: 0.8885 - val_loss: 0.3244 - val_accuracy: 0.8810\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 84s 108ms/step - loss: 0.2778 - accuracy: 0.8983 - val_loss: 0.2776 - val_accuracy: 0.8982\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 86s 110ms/step - loss: 0.2516 - accuracy: 0.9081 - val_loss: 0.2633 - val_accuracy: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x246f3ad75b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_net.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">II. Additional Reading: New Version of ResNet</span> <span style=\"color:red\">**</span> ## \n",
    "This is a **good-to-learn part** and helps you to speculate more recently updated architecture of ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As additional reading, we are going to implement ResNet which is the state-of-the-art convolutional network for image classification and other tasks which took first place in all three ILSVRC 2015 challenges (classification, detection, and localization). \n",
    "\n",
    "ResNet uses **residual blocks** to train Convolutional Neural Networks to depths previously thought impossible. For example, in 2014, the VGG16 and VGG19 architectures were considered very deep. However, with ResNet, we have successfully trained networks with over 100 layers on the challenging ImageNet dataset and over 1,000 layers on CIFAR-10.\n",
    "\n",
    "What we are going to implement is  the **bottleneck residual block** (proposed by He et al. in their 2016 publication, *Identity Mappings in Deep Residual Networks*) used to train deeper networks which is an extension of the **original residual block** proposed in his publication in 2015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.1. The differences between original and bottleneck residual blocks</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows differences between the original residual block and the bottleneck residual block.\n",
    "\n",
    "<img src='imgs/BottleneckResidualBlock.png' align='center' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bottleneck one, each block includes:\n",
    "- ReLU, BATCH-NORM, CONV [filters = K/4, kernel_size = 1x1]\n",
    "- ReLU, BATCH-NORM, CONV [filters = K/4, kernel_size = 3x3]\n",
    "- ReLU, BATCH-NORM, CONV [filters = K, kernel_size = 1x1]\n",
    "- Add inputs and ouputs (residual operation to add shortcut (skip connection) to outputs). This addition is optional for each residual block. In our implementation, when declaring the code for the residual block, we use the parameter `skip_connection` to govern this boolean quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.2. Architecture of ResNet </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet consists of many consecutive ResNet blocks in which each block has several residual blocks. There are many variants of ResNet architecture, which depends on computer vision tasks. The architecture below is an example that solves image classification on Fashion MNIST dataset. The input data are passed through the following layers:\n",
    "- Inputs => BATCH-NORM => CONV.\n",
    "- **ResNet block 1**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_1$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_1$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "- **ResNet block 2**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (2,2)]  (**downsampling image size by $2$**).\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_2$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_2$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "-  ......................\n",
    "- **ResNet block M**\n",
    "  - ***Residual block 1***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (2,2)]  (**downsampling image size by $2$**).\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - Skip connection \n",
    "  - ***Residual block 2***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection \n",
    "  - .........\n",
    "  - ***Residual block $N_M$***\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M/4$, kernel_size = (3,3), strides = (1,1)]\n",
    "    - ReLU, BATCH-NORM, CONV [filters = $K_M$, kernel_size = (1,1), strides = (1,1)]\n",
    "    - No skip connection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">II.3. Implementation of ResNet </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, models, layers, regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "bn_momentum= 0.9\n",
    "bn_eps= 2E-5\n",
    "reg= 0.001\n",
    "DefaultBatchNorm = partial(keras.layers.BatchNormalization, momentum=bn_momentum, epsilon=bn_eps)\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_regularizer=regularizers.l2(reg), use_bias=False, padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self, num_classes=10, batch_size=32, num_epochs=20, optimizer='adam', learning_rate=0.001,\n",
    "                 verbose=True, random_state=42):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = keras.optimizers.get(optimizer)\n",
    "        self.optimizer.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        keras.backend.clear_session()\n",
    "        np.random.seed(self.random_state)\n",
    "        tf.random.set_seed(self.random_state)\n",
    "        self.model = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def ResidualBlock(inputs, K=64, strides= (1,1), skip_connection= False):\n",
    "        main_layers = [DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=int(K/4), kernel_size=1, strides=(1,1)),\n",
    "                       DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=int(K/4), kernel_size=3, strides=strides),\n",
    "                       DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=K, kernel_size=1, strides=(1,1))]\n",
    "        skip_layers = []\n",
    "        if skip_connection:\n",
    "            skip_layers = [DefaultBatchNorm(), layers.Activation(activation='relu'), DefaultConv2D(filters=K, kernel_size=1, strides=strides)]\n",
    "        \n",
    "        h = inputs\n",
    "        for layer in main_layers:\n",
    "            h = layer(h)\n",
    "        \n",
    "        if skip_connection:\n",
    "            short_cut = inputs\n",
    "            for layer in skip_layers:\n",
    "                short_cut = layer(short_cut)\n",
    "            return (h + short_cut)\n",
    "        else:\n",
    "            return h\n",
    "    \n",
    "    def build(self, blocks=[3,4], filters=[16,16,16]):\n",
    "        self.model = models.Model()\n",
    "        inputs = layers.Input(shape=(28, 28, 1))\n",
    "        h = inputs\n",
    "        h = DefaultBatchNorm()(h)\n",
    "        h = DefaultConv2D(filters=filters[0], kernel_size=3)(h)\n",
    "        \n",
    "        for i in range(len(blocks)):\n",
    "            strides = (1,1) if i==0 else (2,2) # We downsample at every beginning residual block except the first ResNet block\n",
    "            h = ResNet.ResidualBlock(h, filters[i], strides, True)  # apply the skip connection on the first residual block\n",
    "            \n",
    "            for j in range(1, blocks[i]-1, 1): # Add more blocks[i]-1 residual models\n",
    "                h  =  ResNet.ResidualBlock(h, filters[i], (1,1), False)  # no skip connection for these residual blocks\n",
    "        \n",
    "        h = DefaultBatchNorm()(h)\n",
    "        h = layers.Activation(activation='relu')(h)\n",
    "        h = layers.AveragePooling2D(pool_size=(8,8))(h)\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(units=self.num_classes, activation=\"softmax\")(h)\n",
    "        self.model = models.Model(inputs=inputs, outputs= h, name=\"ResNet\") # We now have a ResNet model\n",
    "        self.model.compile(optimizer=self.optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None, batch_size=None, num_epochs=None, verbose=None):\n",
    "        batch_size = batch_size if batch_size is not None else self.batch_size\n",
    "        num_epochs = num_epochs if num_epochs is not None else self.num_epochs\n",
    "        verbose = verbose if verbose is not None else self.num_epochs\n",
    "        self.history = self.model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs, verbose=1 if verbose else 0)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, acc = self.model.evaluate(X_test, y_test)\n",
    "        return acc\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        pd.DataFrame(self.history.history).plot(figsize=(8, 5))\n",
    "        plt.grid(True)\n",
    "        plt.gca().set_ylim(0, np.max(self.history.history['loss']))  # Set the vertical range to [0-max(train loss)]\n",
    "        plt.show()\n",
    "    \n",
    "    def summary(self):\n",
    "        print(self.model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 28, 28, 1)    4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 16)   144         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 4)    64          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 4)    16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 28, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 4)    144         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 4)    16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 4)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 16)   64          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 16)   256         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 28, 28, 16)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 16)   64          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 4)    64          activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 4)    16          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 4)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 4)    144         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 4)    16          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 4)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 16)   64          activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 4)    64          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 4)    16          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 28, 28, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 4)    144         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 4)    16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 4)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 16)   64          activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 16)   256         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 14, 14, 16)   0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 14, 14, 16)   64          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 14, 14, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 4)    64          activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 14, 4)    16          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 14, 14, 4)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 4)    144         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 4)    16          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 14, 14, 4)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 16)   64          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 14, 14, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 4)    64          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 14, 14, 4)    16          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 4)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 4)    144         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 14, 14, 4)    16          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 14, 14, 4)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 14, 14, 16)   64          activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 14, 14, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 16)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           170         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,862\n",
      "Trainable params: 2,524\n",
      "Non-trainable params: 338\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "res_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 59s 148ms/step - loss: 1.7172 - accuracy: 0.4048 - val_loss: 1.2107 - val_accuracy: 0.6404\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 1.0072 - accuracy: 0.6986 - val_loss: 0.8855 - val_accuracy: 0.7296\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.8265 - accuracy: 0.7415 - val_loss: 0.8097 - val_accuracy: 0.7522\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.7590 - accuracy: 0.7616 - val_loss: 0.7503 - val_accuracy: 0.7493\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.7222 - accuracy: 0.7713 - val_loss: 0.6979 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "res_net.fit(X_train, y_train, X_valid, y_valid, batch_size=128, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7097 - accuracy: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7799000144004822"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_net.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_net.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
